{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 2., 3.])\n",
      "tensor([ 4., 10., 18.])\n",
      "[1. 2. 3.]\n",
      "tensor([1., 2., 3.])\n",
      "tensor([1., 2., 3.])\n",
      "tensor([[4.],\n",
      "        [5.],\n",
      "        [6.]])\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Mon Mar  9 11:31:23 2020\n",
    "\n",
    "@author: rithik\n",
    "\"\"\"\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms,datasets\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "a=torch.Tensor([1,2,3])\n",
    "b=torch.Tensor([4,5,6])\n",
    "\n",
    "print(a)\n",
    "\n",
    "print(a*b)\n",
    "\n",
    "c=np.array(a)\n",
    "print(c)\n",
    "\n",
    "''' This .Tensor() function is used to convert the numpy array into tensor'''\n",
    "d=torch.Tensor(c)\n",
    "print(d)\n",
    "\n",
    "e=torch.tensor(c)\n",
    "print(e)\n",
    "\n",
    "''' View is similar to reshape'''\n",
    "''' Here for shape input should be a list unlike numpy'''\n",
    "\n",
    "\n",
    "print(b.view((3,1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15000\n",
      "2\n",
      "4\n",
      "4\n",
      "<class 'list'>\n",
      "torch.Size([4, 1, 28, 28])\n",
      "torch.Size([1, 28, 28])\n",
      "torch.Size([28])\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0.])\n",
      "tensor([3, 5, 0, 8])\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAOaklEQVR4nO3df6xU9ZnH8c8jQlDbKGB0UVBKVbLLJgsE0QCuaIWIMYH+oQF1w7pkL3+AoWb/WH9hiRtDs7EYjEnNxR/ApmtthCo2kpaQuuAfVi+KAmVbWYL0ws3FHyg2IUHg2T/uobngnO/cO2dmzlye9yu5mZnzzJl5cvTDOWe+c+Zr7i4A577zym4AQHMQdiAIwg4EQdiBIAg7EMT5zXwzM+Ojf6DB3N0qLS+0Zzez283sj2a218weKvJaABrLah1nN7NBkv4kaaakTknvSZrv7n9IrMOeHWiwRuzZp0ja6+773P24pF9ImlPg9QA0UJGwXynpz70ed2bLzmBmbWbWYWYdBd4LQEFFPqCrdKjwrcN0d2+X1C5xGA+UqcievVPS6F6PR0k6VKwdAI1SJOzvSbrWzL5nZkMkzZO0sT5tAai3mg/j3f2EmS2R9BtJgyS96O6769YZgLqqeeitpjfjnB1ouIZ8qQbAwEHYgSAIOxAEYQeCIOxAEIQdCIKwA0EQdiAIwg4EQdiBIAg7EARhB4Ig7EAQhB0IgrADQRB2IAjCDgRB2IEgCDsQBGEHgiDsQBCEHQiCsANBEHYgCMIOBEHYgSAIOxAEYQeCIOxAEDVP2Yxzw4gRI5L1efPmJetz585N1m+77bbcWrUZhG+99dZk/a233krWcaZCYTez/ZK+lnRS0gl3n1yPpgDUXz327Le4+2d1eB0ADcQ5OxBE0bC7pN+a2XYza6v0BDNrM7MOM+so+F4ACih6GD/N3Q+Z2WWSNpvZ/7r71t5PcPd2Se2SZGbpT2QANEyhPbu7H8puD0v6laQp9WgKQP3VHHYzu8jMvnv6vqRZknbVqzEA9WXVxjpzVzQbq569udRzOvDf7v5klXU4jG+yqVOnJutPPfVUsn7DDTfUs51+OXHiRLL+3HPPJetLly6tZzsDhrtbpeU1n7O7+z5J/1BzRwCaiqE3IAjCDgRB2IEgCDsQBGEHguAS1wFg0qRJyfp9992XW1uyZEly3UGDBtXUUzOcf376f88jR440qZNzA3t2IAjCDgRB2IEgCDsQBGEHgiDsQBCEHQiCcfYWMGTIkGR91apVyXq1y1iL+PDDD5P1lStXJutdXV25tSefTF4Rreuvvz5Z37lzZ7KOM7FnB4Ig7EAQhB0IgrADQRB2IAjCDgRB2IEgGGdvARdeeGGyXmQc/ZtvvknWH3zwwWR9zZo1yfqxY8eS9dQ16dWmXB4/fnyyjv5hzw4EQdiBIAg7EARhB4Ig7EAQhB0IgrADQTDO3gKuuuqqZL3a76M///zzubU333wzue7WrVuT9WquuOKKZH3WrFm5tbvvvju57tNPP52sr1+/PlnHmaru2c3sRTM7bGa7ei0bbmabzezj7HZYY9sEUFRfDuPXSLr9rGUPSdri7tdK2pI9BtDCqobd3bdK+uKsxXMkrc3ur5U0t859AaizWs/ZL3f3Lkly9y4zuyzviWbWJqmtxvcBUCcN/4DO3dsltUuSmXmj3w9AZbUOvXWb2UhJym4P168lAI1Qa9g3SlqQ3V8g6fX6tAOgUcw9fWRtZi9LmiHpUkndkn4s6TVJv5R0laQDku5y97M/xKv0WhzGV3DxxRcn60OHDk3Wu7u7c2vV5jiv9pv1y5YtS9YXLlyYrI8YMSJZTxk1alSynvpN+sjc3Sotr3rO7u7zc0o/KNQRgKbi67JAEIQdCIKwA0EQdiAIwg4EwSWuLeCrr75K1s0qjqT81c0335xbu+mmm5Lrzp49O1m/8cYbk/VGmjlzZrK+bt26JnVybmDPDgRB2IEgCDsQBGEHgiDsQBCEHQiCsANBVL3Eta5vxiWuFV1wwQXJ+ooVK5L1Bx54oJ7t9MvJkyeT9VdeeSW3ds899yTX7ezsTNZvueWWZH3fvn3J+rkq7xJX9uxAEIQdCIKwA0EQdiAIwg4EQdiBIAg7EATXs7eApUuXJutFxtE//fTTZH3btm3JerUpnzdt2pSsp67FnzJlSnLdaj8lPWwYkwf3B3t2IAjCDgRB2IEgCDsQBGEHgiDsQBCEHQiC69lbwNVXX52sP/vss8n62LFjc2uvvvpqct2XXnopWd+/f3+yXsSECROS9dWrVyfr7777brL+8MMP59aOHj2aXHcgq/l6djN70cwOm9muXsuWm9lBM9uR/d1Rz2YB1F9fDuPXSLq9wvKn3X1C9pf+mhWA0lUNu7tvlfRFE3oB0EBFPqBbYmYfZYf5uV9SNrM2M+sws44C7wWgoFrD/jNJ35c0QVKXpJ/mPdHd2919srtPrvG9ANRBTWF39253P+nupyStlpS+fAlA6WoKu5mN7PXwh5J25T0XQGuoOs5uZi9LmiHpUkndkn6cPZ4gySXtl7TI3buqvhnj7DU577z0v8mpa8ar/fc9depUTT01w7Jly5L15cuXJ+vjxo3Lre3du7eWlgaEvHH2qj9e4e7zKyx+oXBHAJqKr8sCQRB2IAjCDgRB2IEgCDsQBD8lPQC08vBYEdOnT0/W77///mR9+/btyfrBgwf73dO5jD07EARhB4Ig7EAQhB0IgrADQRB2IAjCDgTBODtKM3v27GS92k9sr1ixIlk/duxYv3s6l7FnB4Ig7EAQhB0IgrADQRB2IAjCDgRB2IEgGGevgzFjxiTrjZz2eCCbOHFiofXvuuuuZL3alM/RsGcHgiDsQBCEHQiCsANBEHYgCMIOBEHYgSAYZ88MHz48Wd+0aVNu7fHHH0+uG3mc/YknnsitzZgxI7nu5s2bk/V77723lpbCqrpnN7PRZvY7M9tjZrvNbGm2fLiZbTazj7PbYY1vF0Ct+nIYf0LSv7n730q6UdJiM/s7SQ9J2uLu10rakj0G0KKqht3du9z9/ez+15L2SLpS0hxJa7OnrZU0t1FNAiiuX+fsZjZG0kRJv5d0ubt3ST3/IJjZZTnrtElqK9YmgKL6HHYz+46k9ZJ+5O5HzaxP67l7u6T27DW8liYBFNenoTczG6yeoP/c3Tdki7vNbGRWHynpcGNaBFAPVffs1rMLf0HSHndf2au0UdICST/Jbl9vSIdNUm3obfLkybm1wYMH17udljFu3LhkffHixcn6okWLcmtffvllct3HHnssWf/888+TdZypL4fx0yT9k6SdZrYjW/aIekL+SzNbKOmApPTFxQBKVTXs7v62pLwT9B/Utx0AjcLXZYEgCDsQBGEHgiDsQBCEHQiCS1wzBw4cSNa3bduWW9uwYUNuTZIeffTRZH3VqlXJ+vHjx5P1lGrfARg/fnyy/swzzyTr06ZN63dPpw0ZMiRZ/+STT2p+bXwbe3YgCMIOBEHYgSAIOxAEYQeCIOxAEIQdCMLcm/fjMQP5l2omTZqUW0uNwUvS0KFDk/Xdu3cn6x988EGynnLdddcl69dcc02yXu06/2rXlL/22mu5tbfffju57rp165J1VObuFa9SZc8OBEHYgSAIOxAEYQeCIOxAEIQdCIKwA0Ewzt5Hl1xySW7tjTfeSK47derUerfTNEeOHEnW77zzzmT9nXfeqWc76APG2YHgCDsQBGEHgiDsQBCEHQiCsANBEHYgiKrj7GY2WtI6SX8j6ZSkdndfZWbLJf2rpE+zpz7i7m9Wea0BO84ODBR54+x9CftISSPd/X0z+66k7ZLmSrpb0l/c/am+NkHYgcbLC3tf5mfvktSV3f/azPZIurK+7QFotH6ds5vZGEkTJf0+W7TEzD4ysxfNbFjOOm1m1mFmHYU6BVBIn78bb2bfkfQ/kp509w1mdrmkzyS5pP9Qz6H+v1R5DQ7jgQar+ZxdksxssKRfS/qNu6+sUB8j6dfu/vdVXoewAw1W84UwZmaSXpC0p3fQsw/uTvuhpF1FmwTQOH35NH66pG2Sdqpn6E2SHpE0X9IE9RzG75e0KPswL/Va7NmBBit0GF8vhB1oPK5nB4Ij7EAQhB0IgrADQRB2IAjCDgRB2IEgCDsQBGEHgiDsQBCEHQiCsANBEHYgCMIOBFH1Byfr7DNJn/R6fGm2rBW1am+t2pdEb7WqZ29X5xWaej37t97crMPdJ5fWQEKr9taqfUn0Vqtm9cZhPBAEYQeCKDvs7SW/f0qr9taqfUn0Vqum9FbqOTuA5il7zw6gSQg7EEQpYTez283sj2a218weKqOHPGa238x2mtmOsueny+bQO2xmu3otG25mm83s4+y24hx7JfW23MwOZttuh5ndUVJvo83sd2a2x8x2m9nSbHmp2y7RV1O2W9PP2c1skKQ/SZopqVPSe5Lmu/sfmtpIDjPbL2myu5f+BQwz+0dJf5G07vTUWmb2n5K+cPefZP9QDnP3f2+R3parn9N4N6i3vGnG/1klbrt6Tn9eizL27FMk7XX3fe5+XNIvJM0poY+W5+5bJX1x1uI5ktZm99eq53+WpsvprSW4e5e7v5/d/1rS6WnGS912ib6aooywXynpz70ed6q15nt3Sb81s+1m1lZ2MxVcfnqarez2spL7OVvVabyb6axpxltm29Uy/XlRZYS90tQ0rTT+N83dJ0maLWlxdriKvvmZpO+rZw7ALkk/LbOZbJrx9ZJ+5O5Hy+yltwp9NWW7lRH2Tkmjez0eJelQCX1U5O6HstvDkn6lntOOVtJ9egbd7PZwyf38lbt3u/tJdz8labVK3HbZNOPrJf3c3Tdki0vfdpX6atZ2KyPs70m61sy+Z2ZDJM2TtLGEPr7FzC7KPjiRmV0kaZZabyrqjZIWZPcXSHq9xF7O0CrTeOdNM66St13p05+7e9P/JN2hnk/k/0/So2X0kNPXWEkfZn+7y+5N0svqOaz7Rj1HRAsljZC0RdLH2e3wFurtv9QztfdH6gnWyJJ6m66eU8OPJO3I/u4oe9sl+mrKduPrskAQfIMOCIKwA0EQdiAIwg4EQdiBIAg7EARhB4L4f+ZRYQZpzX93AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'dataiter = iter(trainset)\\nimages, labels = dataiter.next()\\nplt.imshow(torchvision.utils.make_grid(images))\\nplt.show()'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train=datasets.MNIST(root=\".\",train=True,download=True,transform=transforms.Compose([transforms.ToTensor()]))\n",
    "\n",
    "test=datasets.MNIST(root=\".\",train=False,download=True,transform=transforms.Compose([transforms.ToTensor()]))\n",
    "\n",
    "trainset=torch.utils.data.DataLoader(train,batch_size=4,shuffle=True)\n",
    "\n",
    "testset=torch.utils.data.DataLoader(test,batch_size=4,shuffle=True)\n",
    "\n",
    "count=0\n",
    "c=[]\n",
    "\n",
    "for data in trainset:\n",
    "    #print(data[1])\n",
    "    c.append(data)\n",
    "    count=count+1\n",
    "    #break\n",
    "\n",
    "print(count)        #(15000*4) no of smaples in the training dataset\n",
    "\n",
    "#x,y=data[0][0],data[1][0]\n",
    "#print(data.get_shape())\n",
    "print(len(data))\n",
    "print(len(data[0]))\n",
    "print(len(data[1]))\n",
    "print(type(data))\n",
    "#print(data.shape)               #data is not a torch object it's a list object so .shape function doesn't work \n",
    "print(data[0].shape)\n",
    "print(data[0][0].shape)\n",
    "print(data[0][0][0][1].shape)\n",
    "print(data[0][0][0][1])          #Tensor object so .shape function works\n",
    "#print(data[0][0])\n",
    "print(data[1])\n",
    "#print(y)\n",
    "\n",
    "%matplotlib inline\n",
    "plt.imshow((np.array(data[0][0])).reshape(28,28),cmap='gray')   #for plotting input has to be numpy array only\n",
    "#spelling of 'gray' is important\n",
    "plt.show()\n",
    "\n",
    "'''\n",
    "first_image = data[0][0]\n",
    "first_image = np.array(first_image, dtype='float')\n",
    "pixels = first_image.reshape((28, 28))\n",
    "plt.imshow(pixels, cmap='gray')\n",
    "plt.show() '''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Training the Neural Networks'''\n",
    "import torch.nn as nn                       #Used for object oriented\n",
    "import torch.nn.functional as F             #used for the Functional Oriented\n",
    "\n",
    "class Net(nn.Module):                       #Here M is capital in Module\n",
    "    def __init__(self):\n",
    "        super().__init__()                  #Don't forget it it's important\n",
    "        self.fc1=nn.Linear(28*28,64)\n",
    "        self.fc2=nn.Linear(64,64)\n",
    "        self.fc3=nn.Linear(64,64)\n",
    "        self.fc4=nn.Linear(64,10)\n",
    "    \n",
    "    \n",
    "    def forward(self,x):                    \n",
    "        #Defines how the data should flow through the network and we are using it as a constructor as self is also\n",
    "        #a parameter\n",
    "        \n",
    "        x=F.relu(self.fc1(x))\n",
    "        x=F.relu(self.fc2(x))\n",
    "        x=F.relu(self.fc3(x))\n",
    "        x=(self.fc4(x))\n",
    "        return F.log_softmax(x,dim=1)     #Here Just like sigmid we calculate something\n",
    "\n",
    "net=Net()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-2.4158, -2.2976, -2.3539, -2.4092, -2.2832, -2.2174, -2.3069, -2.2095,\n",
      "         -2.3460, -2.2128]], grad_fn=<LogSoftmaxBackward>)\n"
     ]
    }
   ],
   "source": [
    "'''Testing For the Randomly Genearted Datasets'''\n",
    "\n",
    "x=torch.rand((28,28))\n",
    "#print(x)\n",
    "x=x.view(1,28*28)                #Here (-1,1) doesn't work\n",
    "output=net(x)\n",
    "\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0030, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0038, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0001, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "'''Training the datasets'''\n",
    "\n",
    "import torch.optim as optim\n",
    "\n",
    "optimiser=optim.Adam(net.parameters(),lr=0.001)\n",
    "\n",
    "num_iter=5\n",
    "\n",
    "for i in range(num_iter):\n",
    "    \n",
    "    for data in trainset:\n",
    "        \n",
    "        X,y=data\n",
    "        \n",
    "        net.zero_grad()                 #As we are training in a batch after a batch the gradient should be zero\n",
    "       \n",
    "        output=net(X.view(-1,28*28))\n",
    "        \n",
    "        loss=F.nll_loss(output,y)       #Generally used if the predicted output is not in the one-hot vector form\n",
    "        \n",
    "        loss.backward()                           #It back propogates the loss calculated\n",
    "        \n",
    "        optimiser.step()                          #Used in adjusting the weights in neural Networks\n",
    "    \n",
    "    print(loss)\n",
    "\n",
    "#Takes a lot of time like approx 3 min depends on the processor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is  98.2\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():                   \n",
    "    # If the data is not used and if we want to test it then gradient shouldn't be applied so we tell this function\n",
    "    # to use if the gradient is not calculated\n",
    "    total=0\n",
    "    count=0\n",
    "    for data in trainset:\n",
    "        x,y = data                                    #Divied into batcches of group 4 as specified during input\n",
    "        output = net(x.view(-1,28*28))\n",
    "        for index,value in enumerate(output):\n",
    "            if(torch.argmax(value)==y[index]):       #It's not output.argmax() its torch.argmax()\n",
    "                count+=1;\n",
    "            total+=1;\n",
    "print(\"Accuracy is \" ,100*round(count/total,3))      #Mostly (97-99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y is  tensor(7)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x[2].view(28,28),cmap='gray')\n",
    "#plt.show()\n",
    "print(\"Y is \",y[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
